name: loadtest-on-gcp
on:
  workflow_call:
    inputs:
      project_id:
        description: 'GCP project id (usualy project_name-NUMBER generated by gcp for you)'
        type: string
        required: true
      location:
        description: 'Kubernetes Engine cluster location'
        type: string
        required: true
      cluster_name:
        description: 'Kubernetes Engine cluster name'
        type: string
        required: true

      geth_image:
        description: 'The geth image to use'
        type: string
        default: 'robustroundrobin/geth:main'

      rrrctl_image:
        description: 'The geth image to use'
        type: string
        default: 'robustroundrobin/rrrctl:main'

      consensus:
        description: 'The name of a consensus scheme supported by benchblock. Eg, raft ibft or rrr'
        type: string
        default: 'raft'
      numnodes:
        description: 'number of nodes required in the network'
        type: string
        default: "3"
      profile:
        description: 'name of a benchblock profile ({consensus}-k8s-{profile}.json in benchblock/configs). defaults to numnodes'
        type: string
      namespaceprefix:
        description: 'prefix to the namespace for all workloads'
        type: string
        default: "benchblock-"

      maxwait:
        description: >
          maximum number of seconds (total) to wait for any intermediate
          result, eg deployment or loadtesting
        type: string
        default: "360"

    secrets:
      gcp_project_key:
        description: >
          GCP service account key with the appropriate roles for applying k8s manifests. Typically
          created in the google cloud console. Eg.,
          IAM & Admin / Service Accounts -> Compute Engine Default Service account -> create key -> create as json
        required: true
jobs:
  loadtest:
    name: loadtest
    runs-on: ubuntu-latest
    steps:

      - id: auth
        uses: google-github-actions/auth@v0
        with:
          credentials_json: ${{ secrets.gcp_project_key }}

      - id: get_credentials
        uses: google-github-actions/get-gke-credentials@v0
        with:
          cluster_name: ${{ inputs.cluster_name }}
          location: ${{ inputs.location }}
          project_id: ${{ inputs.project_id }}

      # It is important the directory is created in the main process. If we let
      # docker create it when it mounts the volume, its created with the wrong
      # ownership and we don't have write access
      - id: prerequisits
        name: prerequisits
        run: |
          mkdir -p networks/${{ inputs.consensus }}${{ inputs.numnodes }}

      - id: bbeth-tag
        uses: oprypin/find-latest-tag@v1
        with:
          repository: robinbryce/benchblock
          releases-only: true

      - id: install-bbeth
        run: |
          ARCH=linux-amd64
          TAG=${{ steps.bbeth-tag.outputs.tag }}
          FILENAME=bbeth-${TAG}-${ARCH}.tar.gz
          URL=https://github.com/robinbryce/benchblock/releases/download/${TAG}/${FILENAME}
          curl -o ${FILENAME} -L $URL
          tar -zxf ${FILENAME}
          chmod a+x bbeth
          ./bbeth --help


      - id: create_network_manifests
        name: create network manifests
        #uses: docker://robinbryce/bbake:main
        uses: docker://robinbryce/bbake:0.4
        with:
          args: >
            new
            --k8s
            --name=${{ inputs.namespaceprefix }}${{ inputs.consensus }}${{ inputs.numnodes }}
            --profile=${{ inputs.numnodes }}
            --geth_image=${{ inputs.geth_image }}
            --rrrctl_image=${{ inputs.rrrctl_image }}
            networks/${{ inputs.consensus }}${{ inputs.numnodes }}
            ${{ inputs.consensus }}

      - id: setup_kustomize
        uses: imranismail/setup-kustomize@v1
        with:
          kustomize-version: "4.3.0"

      - id: render_manifests
        # if this step succeedes, the cleanup task will always run and always
        # try to delete any running pods. apply-network may work but not wait
        # long enough. And its always safe to delete based on the manifests we
        # render here
        name: "render manifests"
        run: |
          MANIFESTSDIR=networks/${{ inputs.consensus }}${{ inputs.numnodes }}/${{ inputs.consensus }}
          kustomize build $MANIFESTSDIR | tee rendered.yaml

      - id: apply_network
        name: deploy network
        run: |
          set -e

          CONSENSUS=${{ inputs.consensus }}
          NUMNODES=${{ inputs.numnodes }}
          NAMESPACE=${{ inputs.namespaceprefix }}${{ inputs.consensus }}${{ inputs.numnodes }}
          CONFIGDIR=networks/${{ inputs.consensus }}${{ inputs.numnodes }}

          BBAKE="docker run --rm -e KUBECONFIG=$KUBECONFIG -v $(pwd):$(pwd) -w $(pwd) robinbryce/bbake:main"

          kubectl -n $NAMESPACE apply -f rendered.yaml

          ${BBAKE} wait-for-network-up $CONFIGDIR

          # ibft and rrr consensus require that blocks are continualy minted.
          # for that style of consensus, we wait for a block to be minted
          # before calling the deployment successful. raft only mints if there
          # are transactions to mine this wont work. but raft is ready to go as
          # soon as the nodes are ready.
          # TODO: if ibft or rrr wait for next block
          [ "${CONSENSUS}" == "raft" ] && echo "raft network ready" && exit 0

          ${BBAKE} wait-for-block $CONFIGDIR
          echo "network ready"

      - id: generate_load
        name: generate transaction load
        run: |

          NAME=${{ inputs.consensus }}${{ inputs.numnodes }}
          NAMESPACE=${{ inputs.namespaceprefix }}$NAME
          CONFIGDIR=networks/${{ inputs.consensus }}${{ inputs.numnodes }}

          BBAKE="docker run --rm -e KUBECONFIG=$KUBECONFIG -v $(pwd):$(pwd) -w $(pwd) robinbryce/bbake:main"

          # raft doesn't mint unless tx's are outstanding
          [ "${CONSENSUS}" == "raft" ] && ${BBAKE} wait-for-block $CONFIGDIR

          kustomize build $CONFIGDIR/jobs/loadtest | kubectl -n $NAMESPACE apply -f -

          ${BBAKE} wait-for-job $CONFIGDIR loadtest
          ENDBLOCK=$(${BBAKE} blocknumber $CONFIGDIR)

          ${BBAKE} collectresults $CONFIGDIR $ENDBLOCK

          cp -v results.db networks/${NAME}/${NAMESPACE}.db

      - id: setup_jupyter
        name: setup jupyter
        uses: docker://robinbryce/bbake:main
        with:
          args: >
            jpycfg networks/${{ inputs.consensus }}${{ inputs.numnodes }}

      - id: generate_graphs
        name: generate graphs
        uses: docker://robinbryce/bbake:main
        with:
          args: >
            jpyrender networks/${{ inputs.consensus }}${{ inputs.numnodes }}

      - id: archive_plots
        name: archive results
        run: |
          NAME=${{ inputs.consensus }}${{ inputs.numnodes }}
          cd networks/${NAME}
          cat parameters.yml
          mkdir -p ../../results-${NAME}-${GITHUB_RUN_NUMBER}
          mv *.png ../../results-${NAME}-${GITHUB_RUN_NUMBER}/
          touch ../../results-${NAME}-${GITHUB_RUN_NUMBER}/DATE-$(date +%F)
          mv standard-plots.html ../../results-${NAME}-${GITHUB_RUN_NUMBER}/
          ls ../../results-${NAME}-${GITHUB_RUN_NUMBER}/
          echo ../../results-${NAME}-${GITHUB_RUN_NUMBER}

      - id: upload_results
        name: upload results
        uses: actions/upload-artifact@v2
        with:
          name: results-${{ inputs.consensus }}${{ inputs.numnodes }}
          path: results-${{ inputs.consensus }}${{ inputs.numnodes }}-*

      - id: delete_network
        name: delete network
        if: always() && steps.render_manifests.outcome == 'success'
        run: |

          NAME=${{ inputs.consensus }}${{ inputs.numnodes }}
          NAMESPACE=${{ inputs.namespaceprefix }}$NAME

          [ ! -f rendered.yaml ] && echo "rendered.yaml missing" && exit 0

          [[ ! $(kubectl -n $NAMESPACE delete -f rendered.yaml 2> /dev/null) ]] \
            && echo "nothing found to delete (or delete failed)" && exit 0
          exit 0
