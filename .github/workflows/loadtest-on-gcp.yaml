name: loadtest-on-gcp
on:
  workflow_call:
    inputs:
      project_id:
        description: 'GCP project id (usualy project_name-NUMBER generated by gcp for you)'
        type: string
        required: true
      location:
        description: 'Kubernetes Engine cluster location'
        type: string
        required: true
      cluster_name:
        description: 'Kubernetes Engine cluster name'
        type: string
        required: true
      consensus:
        description: 'The name of a consensus scheme supported by blockbench. Eg, raft ibft or rrr'
        type: string
        default: 'raft'
      numnodes:
        description: 'number of nodes required in the network'
        type: number
        default: 9
      profile:
        description: 'name of a blockbench profile ({consensus}-k8s-{profile}.json in blockbench/configs). defaults to numnodes'
        type: string
    secrets:
      gcp_project_key:
        description: >
          GCP service account key with the appropriate roles for applying k8s manifests. Typically
          created in the google cloud console. Eg.,
          IAM & Admin / Service Accounts -> Compute Engine Default Service account -> create key -> create as json
        required: true
jobs:
  create-network:
    name: create-network
    runs-on: ubuntu-latest
    steps:

      - id: create-network-manifests
        name: create network manifests
        uses: docker://robinbryce/bbench:main
        with:
          args: >
            new
            --k8s
            --name github-${{ inputs.consensus }}${{ inputs.numnodes }}
            --maxnodes ${{ inputs.numnodes }}
            --profile ${{ inputs.numnodes }}
            networks/${{ inputs.consensus }}${{ inputs.numnodes }}
            ${{ inputs.consensus }}

      - id: setup-jupyter
        name: setup jupyter
        uses: docker://robinbryce/bbench:main
        with:
          args: >
            jpycfg networks/${{ inputs.consensus }}${{ inputs.numnodes }}

      - id: setup-kustomize
        uses: imranismail/setup-kustomize@v1
        with:
          kustomize-version: "4.3.0"

      - id: get-credentials
        uses: google-github-actions/get-gke-credentials@main
        with:
          cluster_name: ${{ inputs.cluster_name }}
          location: ${{ inputs.location }}
          project_id: ${{ inputs.project_id }}
          credentials: ${{ secrets.gcp_project_key }}

      - id: apply-network
        name: deploy network
        run: |

          ATTEMPTS_REMAINING=40

          # clean up any previous attempt

          NAME=${{ inputs.consensus }}${{ inputs.numnodes }}

          NAMESPACE=github-$NAME

          kustomize build networks/$NAME/${{ inputs.consensus }} \
            | tee $NAME-rendered.yaml

          NRUNNING=$(kubectl -n $NAMESPACE \
            get pods --selector=app.kubernetes.io/part-of=ethnet \
            --output=jsonpath={.items..metadata.name} | wc -w)

          if [ "$NRUNNING" != "0" ]; then

            set +e
            kustomize build networks/$NAME/${{ inputs.consensus }} \
              | kubectl -n $NAMESPACE \
                  delete -f $NAME-rendered.yaml

            while [ "$NRUNNING" != "0" ]; do

              [ "$ATTEMPTS_REMAINING" == "0" ] && exit -1

              ATTEMPTS_REMAINING=$((ATTEMPTS_REMAINING - 1))

              NRUNNING=$(kubectl -n $NAMESPACE \
                get pods --selector=app.kubernetes.io/part-of=ethnet \
                --output=jsonpath={.items..metadata.name} | wc -w)

              echo "Waiting for $NRUNNING to terminate (attempts left $ATTEMPTS_REMAINING)"
              sleep 2
            done
            set -e
          fi

          set -e
          kustomize build networks/$NAME/${{ inputs.consensus }} \
            | kubectl -n $NAMESPACE apply -f $NAME-rendered.yaml

      - id: wait-for-startup
        name: wait for network to start
        run: |

          ATTEMPTS_REMAINING=30

          # this can all be finessed once the basics are working
          NAMESPACE=github-${{ inputs.consensus }}${{ inputs.numnodes }}

          while true; do
            NRUNNING=$(kubectl -n $NAMESPACE get pods \
              --field-selector=status.phase=Running \
              --output=jsonpath={.items..metadata.name} | wc -w)

            [ "${NRUNNING}" == "${{ inputs.numnodes }}" ] && break

            [ "$ATTEMPTS_REMAINING" == "0" ] && exit -1
            ATTEMPTS_REMAINING=$((ATTEMPTS_REMAINING - 1))

            echo "${NRUNNING} of ${{ inputs.numnodes }} running sleeping for 4s (attempts left $ATTEMPTS_REMAINING)"
            sleep 4
          done

      - id: checkout-main
        uses: actions/checkout@v2
        with:
          path: main

      - id: setup-go
        uses: actions/setup-go@v2
        with:
          go-version: 1.15.15

      - id: generate-load
        name: generate transaction load
        run: |

          ATTEMPTS_REMAINING=100
          NAME=${{ inputs.consensus }}${{ inputs.numnodes }}
          NAMESPACE=github-$NAME

          pushd networks/${{ inputs.consensus }}${{ inputs.numnodes }}
          RESULTSDIR=$(pwd)

          STARTBLOCK=$(kubectl exec -n $NAMESPACE ethnode0-0 -- \
            geth attach /data/node/geth.ipc \
              --exec eth.blockNumber)

          kustomize build jobs/loadtest \
          | kubectl -n $NAMESPACE \
              apply -f -
          echo "waiting for job to complete"

          # this can all be finessed once the basics are working
          while true; do
            echo "sleep 4s"
            sleep 4
            state=$(kubectl  -n $NAMESPACE get pods \
              --selector=job-name=loadtest -o jsonpath='{.items[0].status.containerStatuses[0].state.terminated.reason}')
            echo "State: $state"
            [ "$state" == "Completed" ] && break

            [ "$ATTEMPTS_REMAINING" == "0" ] && exit -1
            ATTEMPTS_REMAINING=$((ATTEMPTS_REMAINING - 1))

          done

          popd

          pwd

          # TODO bbencheth collect the blocks
          echo "loadtest complete"
          kubectl port-forward -n $NAMESPACE ethnode0-0 8300:8300 &
          PF_PID=$!

          cd main/go/bbencheth
          echo ${RESULTSDIR}
          ls -la ${RESULTSDIR}/
          echo "STARTBLOCK: $STARTBLOCK"

          echo "STARTBLOCK: $STARTBLOCK"
          go run main.go -e http://localhost:8300 --no_progress \
            --dbsource ${RESULTSDIR}/${NAME}.db \
            collect -s $STARTBLOCK -x 1800

          ls -la ${RESULTSDIR}/${NAME}.db


      - id: generate-graphs
        name: generate graphs
        uses: docker://robinbryce/bbench:main
        with:
          args: >
            jpyrender networks/${{ inputs.consensus }}${{ inputs.numnodes }}

      - id: archive-plots
        name: archive results
        run: |
          cd networks/${{ inputs.consensus }}${{ inputs.numnodes }}
          zip standard-plots.${GITHUB_RUN_NUMBER}.zip *.jpg
          mv standard-plots.html standard-plots.${GITHUB_RUN_NUMBER}.html

      - id: upload-results
        uses: actions/upload-artifact@v2
        with:
          name: standard-plots
          path: |
            networks/${{ inputs.consensus }}${{ inputs.numnodes }}/standard-plots.${GITHUB_RUN_NUMBER}.html
            networks/${{ inputs.consensus }}${{ inputs.numnodes }}/standard-plots.${GITHUB_RUN_NUMBER}.zip


