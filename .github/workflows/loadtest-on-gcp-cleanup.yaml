name: loadtest-on-gcp-cleanup
on:
  workflow_call:
    inputs:
      project_id:
        description: 'GCP project id (usualy project_name-NUMBER generated by gcp for you)'
        type: string
        required: true
      location:
        description: 'Kubernetes Engine cluster location'
        type: string
        required: true
      cluster_name:
        description: 'Kubernetes Engine cluster name'
        type: string
        required: true
      consensus:
        description: 'The name of a consensus scheme supported by benchblock. Eg, raft ibft or rrr'
        type: string
        default: 'raft'
      numnodes:
        description: 'number of nodes required in the network'
        type: string
        default: "3"
      profile:
        description: 'name of a benchblock profile ({consensus}-k8s-{profile}.json in benchblock/configs). defaults to numnodes'
        type: string
    secrets:
      gcp_project_key:
        description: >
          GCP service account key with the appropriate roles for applying k8s manifests. Typically
          created in the google cloud console. Eg.,
          IAM & Admin / Service Accounts -> Compute Engine Default Service account -> create key -> create as json
        required: true
jobs:
  cleanup-network:
    name: cleanup-network
    runs-on: ubuntu-latest
    steps:
      # It is important the directory is created in the main process. If we let
      # docker create it when it mounts the volume, its created with the wrong
      # ownership and we don't have write access
      - id: prerequisits
        name: prerequisits
        run: |
          mkdir -p networks/${{ inputs.consensus }}${{ inputs.numnodes }}

      - id: create-network-manifests
        name: create network manifests
        uses: docker://robinbryce/bbench:main
        with:
          args: >
            new
            --k8s
            --name github-${{ inputs.consensus }}${{ inputs.numnodes }}
            --maxnodes ${{ inputs.numnodes }}
            --profile ${{ inputs.numnodes }}
            networks/${{ inputs.consensus }}${{ inputs.numnodes }}
            ${{ inputs.consensus }}
      - id: setup-kustomize
        uses: imranismail/setup-kustomize@v1
        with:
          kustomize-version: "4.3.0"

      - id: get-credentials
        uses: google-github-actions/get-gke-credentials@main
        with:
          cluster_name: ${{ inputs.cluster_name }}
          location: ${{ inputs.location }}
          project_id: ${{ inputs.project_id }}
          credentials: ${{ secrets.gcp_project_key }}

      - id: delete-network
        name: delete network
        run: |

          ATTEMPTS_REMAINING=120
          SLEEP=2
          NUMNODES=${{ inputs.numnodes }}
          NAMESPACE=github-${{ inputs.consensus }}${{ inputs.numnodes }}
          MANIFESTSDIR=networks/${{ inputs.consensus }}${{ inputs.numnodes }}/${{ inputs.consensus }}

          # delete any previous network first

          NRUNNING=$(kubectl -n $NAMESPACE \
            get pods --selector=app.kubernetes.io/part-of=ethnet \
            --output=jsonpath={.items..metadata.name} | wc -w)

          if [ "$NRUNNING" != "0" ]; then

            set +e
            kustomize build ${MANIFESTSDIR} > rendered.yaml
            kubectl -n $NAMESPACE delete -f rendered.yaml

            while [ "$NRUNNING" != "0" ]; do

              [ "$ATTEMPTS_REMAINING" == "0" ] && exit -1
              ATTEMPTS_REMAINING=$((ATTEMPTS_REMAINING - 1))

              NRUNNING=$(kubectl -n $NAMESPACE \
                get pods --selector=app.kubernetes.io/part-of=ethnet \
                --output=jsonpath={.items..metadata.name} | wc -w)

              echo "Waiting for $NRUNNING to terminate (attempts left $ATTEMPTS_REMAINING, sleeping for ${SLEEP}s)"
              sleep ${SLEEP}
            done
            set -e
          fi
