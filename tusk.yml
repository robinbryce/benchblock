interpreter: bash -c
name: bbake
usage: |

  Use the `new' command to create a full configuration for a supported
  consensus scheme. A number of pre-configured profiles are available and are
  selected as the default basis depending on the consensus chosen. For example

    `bbake new . raft`

  Will create a raft network configuration using the default profile for a raft
  docker-compose based network (configs/raft-compose-default.json). And

    `bbake new --k8s --maxnodes 9 . raft`

  Will select configs/raft-k8s-9.json - which configures a raft network with 9
  nodes and generates a deployable (kustomize based) set of kubernetes
  manifiests.

  The values configured by the profile can be overriden individualy by
  corresponding command line options.

  `new -i' will perform the configuration without generatng keys or other
  genesis materials.

  `raft`, `ibft` and `rrr`, respectively, will generate (or regenerate) the
  genesis materials and any related network configuration necessary in order to
  start a chain. The appropriate command from this set is invoked automatically
  by `new` unless -i is set.

  `gethkeys' and `gethgendoc' are used to generate the node keys and genesis
  document for all consensus models (and to force re-genesis). commands
  prefixed with `raft', `rrr', or `ibft' deal with coresponding consensus
  schemes.

  The various sub commands can be useful if you want to regenerate keys, reset
  a chain or perform other maintenance on a configuration without reseting it
  completely. Review the definition of the main conesnsus commands `raft',
  `ibft' and 'rrr' to see the individual commands that effect each.

  `jpcfg' readies a network configuration for collecting chainhammer compatible
  block data and `jpyrender' processes the data collected by the load
  generation tool [see ](./go/bbeth/main.go)

  The other commands provide various conveniences

options:

  # general options ---
  blockperiod:
    usage: >
      ibft - sets the interval between blocks

  composeproject:
    usage: alternate docker compose project name
    default: ""

  gaslimit:
    usage: sets the --miner.gaslimit option for the nodes
    # default: "18200000"
  gastarget:
    usage: sets the --miner.gastarget option for the nodes
    # default: "18200000"
  gendoc_balance:
    default: "1000000000000000000000000000"
  gendoc_wallet:
    usage: >
      This wallet address will be included in the gensis document allocs.
      Its balance is set by gendoc_balance. This is a convenience that
      enables the same wallet key to be re-used accross multiple
      configurations.
    default: ""
  genesis:
    default: genesis-in.json
    short: "g"
  geth_image:
    usage: geth client the docker iamge
    default: ""

  etherbase:
    default: ""

  k8s:
    usage: >
      Generate a set of kubernetes manifiests (kustomizations) instead of
      the default docker-compose setup.
    type: bool
    short: k

  maxnodes:
    usage: >
      The number of nodes for the network. For PoA networks, it is the number
      of *validating* nodes.
    default: ""
    short: "n"
  name:
    usage: >
      The network name, defaults to <consensus><maxnodes>
    default: ""

  node-namespace:
    usage: >
      The namespace nodes are put in for k8s, defaults to <consensus><maxnodes>
    default: ""

  netrestrict:
    default: ""

  chainid:
    default: ""
  networkid:
    default: ""
  nodesdir:
    usage: >
      each node gets a subdirectory here named node{N}. relative paths are
      relative to the callers cwd.  defaults to <consensus>/nodes
    default: ""
  nodeallocs:
    usage: >
      How many of the node keys to create alloc accounts for. The ballance
      is set to gendoc_balance for all.
    default: 0

  pyenv:
    usage: >
      Override the directory to create the python virtualenv in. By default
      there is an env per network. This option can be used to share the env.
      By default it will be called env and created in the configdir
    default: ""

  # feature: apisec
  apisec:
    usage: >
      Require a valid "Authorization: Bearer TOKEN" header for json-rpc access.
      Token aud must be the node identity, the requested method must in in the
      scopes (which can be wild carded)
      Only available for k8s manifests
    type: bool

  apisec-certname:
    usage: >
      The name of the kubernetes secret to expect the traefik ingress tls certificate in
      defaults to "wild-nodes-cert"

  apisec-ingresshost:
    usage: >
      enable the traefik ingress route and set the hostname

  apisec-tokenex:
    usage: >
      address of the token exchange 'scheme://host:port/path'

  apisec-nodepath:
    usage: >
      specify an alternate node path. so that the uri for the node is
      {apisec-nodepath}/ethnode{N}. defaults to /node

  apisec-issuer:
    usage: >
      access tokens are required to contain this issuer in their iss claim
  apisec-jws:
    usage: >
      The url of the json webkey set for verifying tokens

  # feature: nodeports
  nodeports:
    usage: >
      Expose all nodes via nodeports
    type: bool

  nodeports-base:
    usage: >
      This option sets the port allocated to the first node. NodePorts must be
      in the range 30000-32767. The port exposes the p2p traffic for the node

  nodeports-stride:
    usage: >
      This option sets the increment added to the node port for each successive
      node. This allows for nodes to have groups of related ports.

  # feature: sealedsecrets
  sealedsecrets-cert:
    usage: >
      path to the public key to seal the secrets with
  sealedsecrets-namespace:
    usage: >
      the namespace for the sealedsecrets
  sealedsecrets-controller-namespace:
    usage: >
      the namespace the bitnami/sealedsecrets controller is deployed in

  # source options. only used for compose networks and then only if
  # interactively debuging the node
  quorum_src:
    usage: >
      the host directory to be mounted as /go/src/quorum. must contain quorum
      clone.  only required if you need to interactively debug the node.
    default:
      command: echo ""
  # raft options ---
  recommit:
    usage: >
      sets the --miner.recommit option for the nodes. currently set high
      because it invalidates the current round intent if it fires mid round
    default: ""

  raftblocktime:
    usage: >
      raft - time between blocks

  # rrr options
  rrr_image:
    usage: rrr - docker image of a geth client with rrr support
    default: ""
  rrrctl_image:
    usage: rrr - docker image for rrrctl (needed to produce rrr extraData)
    default: ""
  rrr_src:
    default:
      command: echo ""
  activehorizon:
    usage: >
      rrr - identities that don't record activity in this number of rounds are
      culled (Ta from the paper)
    default: ""
  activemethod:
    usage: >
      rrr - chose how the active selection is managed (this is a rrr developer
      option)
    default: ""

  committeequorum:
    usage: >
      rrr - required number of endorsements in a round required to mine a block
    default: ""
  confirmphase:
    usage: >
      rrr - number of milli seconds to allow wait for endorsements for the
      intents
  intentphase:
    usage: >
      rrr - number of milli seconds to allow for leader candidate intents to
      arrive
    default: ""
  numcandidates:
    usage: >
      rrr - number of leader candidates in a round. must be the same for all
      nodes. NOTICE: this option will be moved to genesis config eventually
    default: ""
  numendorsers:
    usage: >
      rrr - number of endorsers in a round. must be the same for all nodes.
      NOTICE: this option will be moved to genesis config eventually
    default: ""
  roundlength:
    usage: >
      rrr - number of milli seconds for the total round. intentphase +
      confirmphase must be less than this and the *remainder* is time to allow
      for the new block to be diseminated around the network
    default: ""

  # treat the following as private even if they are not
  launchdir:
    # treat this as private
    usage: >
      Don't set this option. Its a work around for a go-tusk peculiarity
    environment: PWD

  config:
    private: true
    usage: >
      Base filename of the config file to use in configdir. Enables alternate
      configs for the same network.
    default:
      bench.json
  configshow:
    usage: "Report which, if any, supported configdir config file VAR's"
    type: bool
  # private vars
  thistusk:
    private: true
    usage: "so this tusk file can refer to its own file name for recursive execution"
    default:
      command: echo $(pwd)/tusk.yml

  tuskdir:
    private: true
    usage: "so all tasks can refer to the directory containing this tusk file"
    default:
      command: echo $(pwd)

  ibftvars:
    private: true
    usage: >
      Config vars exclusive to ibft
    default: >-
      blockperiod
      requesttimeout

  raftvars:
    private: true
    usage: >
      Config vars exclusive to raft
    default: >-
      raftblocktime

  rrrvars:
    private: true
    usage: >
      Config vars exclusive to rrr
    default: >-
      activemethod
      activehorizon
      committeequorum
      confirmphase
      intentphase
      numcandidates
      numendorsers
      roundlength
      rrr_image
      rrr_src
      rrrctl_image

  configvars:
    private: true
    usage: >
      All supported configuration variabes. All can be set by `new` when
      creating the configuration. Consensus specific sub commands can be used
      to update them later.
    default: >-
      apisec
      apisec-certname
      apisec-ingresshost
      apisec-issuer
      apisec-jws
      apisec-nodepath
      apisec-tokenex
      nodeports
      nodeports-base
      nodeports-stride
      bootnode0
      composeproject
      consensus
      consensus_opts
      chainid
      delve_image
      etherbase
      features
      gaslimit
      gastarget
      gendoc_balance
      gendoc_extra
      gendoc_wallet
      genesis
      geth_image
      k8s
      maxnodes
      name
      node-namespace
      netrestrict
      networkid
      nodeallocs
      nodesdir
      numbootnodes
      pyenv
      quorum_src
      recommit
      sealedsecrets-cert
      sealedsecrets-namespace
      sealedsecrets-controller-namespace
      ${ibftvars}
      ${raftvars}
      ${rrrvars}

tasks:

  loadtest:
    include: tuskfiles/loadtool.yml

  new:
    usage: >
      Configure a new network configdir from a stock profile
    options:
      profile:
        short: "p"
        usage: provide the default configuration values
      init-only:
        type: bool
        short: "i"
      context:
        usage: "kubernetes (kubectl) config context to use. Ignored unless the profile enables k8s manifiests"
        short: "c"
        default: ""

    args:
      configdir:
      consensus:
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e

            echo "launchdir: ${launchdir}"

            # Any options set on the command line are transalted here to
            # BBENCH_ env vars. This has the effect that cli options have
            # highest priority and will always make it to the bench.json config
            # BBAKE_ env vars, if set (and possibly empty), will only make it
            # through if the correspoding cli option is not set. Note that this
            # section is the single source of truth for the supported cli
            # configuration options. Other config values may be permited using
            # profiles but, if they are not listed here, they can only be set
            # in the profile. The configvars task lists the full set of
            # variables that are significant in banch.json (any other entries
            # are ignored)
            #
            # [ -n "${K8S}" ] && BBAKE_K8S=
            BBAKE_CONSENSUS=${consensus}

            ${apisec} && export BBAKE_APISEC="true" && export BBAKE_FEATURES="$BBAKE_FEATURES apisec"
            ${nodeports} && export BBAKE_NODEPORTS="true" && export BBAKE_FEATURES="$BBAKE_FEATURES nodeports"
            [ -n "${sealedsecrets-cert}" ] && export BBAKE_SEALEDSECRETS_CERT=${sealedsecrets-cert} && export BBAKE_FEATURES="$BBAKE_FEATURES sealedsecrets"
            [ -n "${sealedsecrets-namespace}" ] && export BBAKE_SEALEDSECRETS_NAMESPACE=${sealedsecrets-namespace}
            [ -n "${sealedsecrets-controller-namespace}" ] && export BBAKE_SEALEDSECRETS_CONTROLLER_NAMESPACE=${sealedsecrets-controller-namespace}
            [ -n "${apisec-certname}" ] && export BBAKE_APISEC_CERTNAME=${apisec-certname}
            [ -n "${apisec-ingresshost}" ] && export BBAKE_APISEC_INGRESSHOST=${apisec-ingresshost}
            [ -n "${apisec-issuer}" ] && export BBAKE_APISEC_ISSUER=${apisec-issuer}
            [ -n "${apisec-jws}" ] && export BBAKE_APISEC_JWS=${apisec-jws}
            [ -n "${apisec-nodepath}" ] && export BBAKE_APISEC_NODEPATH=${apisec-nodepath}
            [ -n "${apisec-tokenex}" ] && export BBAKE_APISEC_TOKENEX=${apisec-tokenex}

            [ -n "${nodeports-base}" ] && export BBAKE_NODEPORTS_BASE=${nodeports-base}
            [ -n "${nodeports-stride}" ] && export BBAKE_NODEPORTS_STRIDE=${nodeports-stride}
            [ -n "${composeproject}" ] && export BBAKE_COMPOSEPROJECT=${composeproject}
            [ -n "${etherbase}" ] && export BBAKE_ETHERBASE=${etherbase}
            [ -n "${gaslimit}" ] && export BBAKE_GASLIMIT=${gaslimit}
            [ -n "${gastarget}" ] && export BBAKE_GASTARGET=${gastarget}
            [ -n "${gendoc_ballance}" ] && export BBAKE_GENDOC_BALANCE=${gendoc_ballance}
            [ -n "${gensis}" ] && export BBAKE_GENESIS=${genesis}
            [ -n "${geth_image}" ] && export BBAKE_GETH_IMAGE=${geth_image}
            [ -n "${maxnodes}" ] && export BBAKE_MAXNODES=${maxnodes}
            [ -n "${name}" ] && export BBAKE_NAME=${name}
            [ -n "${node-namespace}" ] && export BBAKE_NODE_NAMESPACE=${node-namespace}
            [ -n "${chainid}" ] && export BBAKE_CHAINID=${chainid}
            [ -n "${networkid}" ] && export BBAKE_NETWORKID=${networkid}
            [ -n "${netrestrict}" ] && export BBAKE_NETRESTRICT=${netrestrict}
            [ -n "${nodeallocs}" ] && export BBAKE_NODEALLOCS=${nodeallocs}
            # [ -n "${nodesdir}" ] && export BBAKE_NODESDIR=${nodesdir} handled in the
            # PYEND block below
            [ -n "${numbootnodes}" ] && export BBAKE_NUMBOOTNODES=${numbootnodes}
            [ -n "${pyenv}" ] && export BBAKE_PYENV=${pyenv}
            [ -n "${quorum_src}" ] && export BBAKE_QUORUM_SRC=${quorum_src}
            [ -n "${recommit}" ] && export BBAKE_RECOMMIT=${recommit}
            # ibft
            [ -n "${blockperiod}" ] && export BBAKE_BLOCKPERIOD=${blockperiod}
            # raft
            [ -n "${raftblocktime}" ] && export BBAKE_RAFTBLOCKTIME=${raftblocktime}
            # rrr
            [ -n "${activemethod}" ] && export BBAKE_ACTIVEMETHOD=${activemethod}
            [ -n "${activehorizon}" ] && export BBAKE_ACTIVEHORIZON=${activehorizon}
            [ -n "${committeequorum}" ] && export BBAKE_COMMITTEEQUORUM=${committeequorum}
            [ -n "${intentphase}" ] && export BBAKE_INTENTPHASE=${intentphase}
            [ -n "${confirmphase}" ] && export BBAKE_CONFIRMPHASE=${confirmphase}
            [ -n "${numcandidates}" ] && export BBAKE_NUMCANDIDATES=${numcandidates}
            [ -n "${numendorsers}" ] && export BBAKE_NUMENDORSERS=${numendorsers}
            [ -n "${roundlength}" ] && export BBAKE_ROUNDLENGTH=${roundlength}
            [ -n "${rrr_image}" ] && export BBAKE_RRR_IMAGE=${rrr_image}
            [ -n "${rrr_src}" ] && export BBAKE_RRR_SRC=${rrr_src}
            [ -n "${rrrctl_image}" ] && export BBAKE_RRRCTL_IMAGE=${rrrctl_image}

            # If we don't have feature sealedsecrets force devnodekeys. Its a
            # bit crude but it will serve for now
            if echo "$BBAKE_FEATURES" | grep -v sealedsecrets; then
              export BBAKE_FEATURES="$BBAKE_FEATURES devnodekeys"
            fi

            deploymode="k8s"
            [ "${k8s}" != true ] && deploymode="compose"

            python3 ${tuskdir}/benchjson.py new-config \
              --profile=${profile} \
              --tuskdir=${tuskdir} \
              --launchdir=${launchdir} \
              --configdir=${configdir} \
              --consensus=${BBAKE_CONSENSUS} \
              --deploymode=${deploymode} \
              --nodesdir=${nodesdir} \
              ${config} \
              ${configvars}

            cd ${launchdir} && cd ${configdir}

            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)

            echo "creating pyenv using: $(which python3)"
            python3 -m venv ${BBAKE_PYENV}
            source ${BBAKE_PYENV}/bin/activate
            pip3 install -r ${tuskdir}/requirements.txt

            [ -d ${tuskdir}/k8s/${BBAKE_CONSENSUS} ] && mkdir -p ${BBAKE_CONSENSUS}

            if ${k8s} || ${BBAKE_K8S}; then
              [ -d ${tuskdir}/k8s/components ] && mkdir -p components && cp -r ${tuskdir}/k8s/components/* components
              [ -d ${tuskdir}/k8s/base ] && mkdir -p base && cp -r ${tuskdir}/k8s/base/* base
              [ -d ${tuskdir}/k8s/jobs ] && mkdir -p jobs && cp -r ${tuskdir}/k8s/jobs/* jobs
              [ -d ${tuskdir}/k8s/${BBAKE_CONSENSUS} ] && cp -r ${tuskdir}/k8s/${BBAKE_CONSENSUS}/* ${BBAKE_CONSENSUS}
            fi

            cat bench.json

      - when:
          equal: {init-only: false}
        command:
          exec: |
            set -e
            cd ${launchdir}
            tusk -qf ${tuskdir}/tusk.yml ${consensus} ${configdir}

  ibft:
    usage: >
      Configure, or reconfigure, an ibft network

    args:
      configdir:
        usage: Directory to put the network in
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e

            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            if ${configshow}; then eval ${SHOW_CONFIG}; fi

            [ "${BBAKE_CONSENSUS}" != "ibft" ] && echo "Configured for ${BBAKE_CONSENSUS} not ibft" && exit 1

            # prioritize any options over environment and profile.
            [ -n "${gaslimit}" ] && export BBAKE_GASLIMIT=${gaslimit}
            [ -n "${gastarget}" ] && export BBAKE_GASTARGET=${gastarget}
            [ -n "${gendoc_ballance}" ] && export BBAKE_GENDOC_BALANCE=${gendoc_ballance}
            [ -n "${gensis}" ] && export BBAKE_GENESIS=${genesis}
            [ -n "${geth_image}" ] && export BBAKE_GETH_IMAGE=${geth_image}
            [ -n "${maxnodes}" ] && export BBAKE_MAXNODES=${maxnodes}
            # export BBAKE_NAME=
            [ -n "${networkid}" ] && export BBAKE_NETWORKID=${networkid}
            [ -n "${nodeallocs}" ] && export BBAKE_NODEALLOCS=${nodeallocs}
            # export BBAKE_NODESDIR=
            [ -n "${numbootnodes}" ] && export BBAKE_NUMBOOTNODES=${numbootnodes}
            # export BBAKE_PYENV=
            [ -n "${quorum_src}" ] && export BBAKE_QUORUM_SRC=${quorum_src}
            [ -n "${recommit}" ] && export BBAKE_RECOMMIT=${recommit}

            # ibft specific options
            [ -n "${blockperiod}" ] && export BBAKE_BLOCKPERIOD=${BBAKE_BLOCKPERIOD}
            [ -n "${requesttimeout}" ] && export BBAKE_REQUESTTIMEOUT=${requesttimeout}

            cd ${launchdir} && cd ${configdir}

            ${UPDATE_CONFIG}
            cat bench.json

      - task:
          name: gethkeys
          args:
            - ${configdir}
      - task:
          name: ibftextra
          args:
            - ${configdir}
      - task:
          name: gethstatic
          args:
            - ${configdir}
      - task:
          name: gethgen
          args:
            - ${configdir}

      - task:
          name: clientcfg
          args:
            - ${configdir}

      - task:
          name: ibftopts
          args:
            - ${configdir}

      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)

            CMD=gethcompose
            ${BBAKE_K8S} && CMD=gethk8s

            cd ${launchdir}
            tusk -qf ${tuskdir}/tusk.yml ${CMD} ${configdir}

  raft:
    usage: >
      Configure, or reconfigure, a raft network
    args:
      configdir:
        usage: Directory to put the network in
    run:
      - task:
          name: configure
          args:
            - ${configdir}

      - command:
          exec: |
            set -e

            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            if ${configshow}; then eval ${SHOW_CONFIG}; fi

            [ "${BBAKE_CONSENSUS}" != "raft" ] && echo "Configured for ${BBAKE_CONSENSUS} not raft" && exit 1

            # prioritize any options over environment and profile.
            [ -n "${gaslimit}" ] && export BBAKE_GASLIMIT=${gaslimit}
            [ -n "${gastarget}" ] && export BBAKE_GASTARGET=${gastarget}
            [ -n "${gendoc_ballance}" ] && export BBAKE_GENDOC_BALANCE=${gendoc_ballance}
            [ -n "${gensis}" ] && export BBAKE_GENESIS=${genesis}
            [ -n "${geth_image}" ] && export BBAKE_GETH_IMAGE=${geth_image}
            [ -n "${maxnodes}" ] && export BBAKE_MAXNODES=${maxnodes}
            # export BBAKE_NAME=
            [ -n "${networkid}" ] && export BBAKE_NETWORKID=${networkid}
            [ -n "${nodeallocs}" ] && export BBAKE_NODEALLOCS=${nodeallocs}
            # export BBAKE_NODESDIR=
            [ -n "${numbootnodes}" ] && export BBAKE_NUMBOOTNODES=${numbootnodes}
            # export BBAKE_PYENV=
            [ -n "${quorum_src}" ] && export BBAKE_QUORUM_SRC=${quorum_src}
            [ -n "${recommit}" ] && export BBAKE_RECOMMIT=${recommit}

            [ -n "${raftblocktime}" ] && export BBAKE_RAFTBLOCKTIME=${raftblocktime}

            # prioritize commandline setting for raft blocktime. if its not
            # already set (by the profile or by hand) force it to 50 (the
            # quorum default)
            [ -z "${RAFT_RAFTBLOCKTIME}" ] && RAFT_RAFTBLOCKTIME=50

            cd ${launchdir} && cd ${configdir}
            ${UPDATE_CONFIG}
            cat bench.json

      - task:
          name: gethkeys
          args:
            - ${configdir}
      - task:
          name: gethstatic
          options:
            querystring: "?discport=0&raftport=50000"
          args:
            - ${configdir}
      - task:
         name: gethgen
         args:
           - ${configdir}

      - task:
          name: clientcfg
          args:
            - ${configdir}

      - task:
          name: raftopts
          args:
            - ${configdir}

      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)

            cd ${launchdir}
            CMD=gethcompose
            ${BBAKE_K8S} && CMD=gethk8s
            tusk -qf ${tuskdir}/tusk.yml ${CMD} ${configdir}

  rrr:
    usage: >
      Configure, or re-configure, an rrr network
      # This task also ilustrates the full sequence of steps to prepare an rrr
      # compose setup
    args:
      configdir:
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e

            # read the config file fields into BBAKE_ vars.
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            if ${configshow}; then eval ${SHOW_CONFIG}; fi

            [ "${BBAKE_CONSENSUS}" != "rrr" ] && echo "Configured for ${BBAKE_CONSENSUS} not rrr" && exit 1

            # prioritize any options over environment and profile.
            [ -n "${gaslimit}" ] && export BBAKE_GASLIMIT=${gaslimit}
            [ -n "${gastarget}" ] && export BBAKE_GASTARGET=${gastarget}
            [ -n "${gendoc_ballance}" ] && export BBAKE_GENDOC_BALANCE=${gendoc_ballance}
            [ -n "${gensis}" ] && export BBAKE_GENESIS=${genesis}
            [ -n "${geth_image}" ] && export BBAKE_GETH_IMAGE=${geth_image}
            [ -n "${maxnodes}" ] && export BBAKE_MAXNODES=${maxnodes}
            # export BBAKE_NAME=
            [ -n "${networkid}" ] && export BBAKE_NETWORKID=${networkid}
            [ -n "${nodeallocs}" ] && export BBAKE_NODEALLOCS=${nodeallocs}
            # export BBAKE_NODESDIR=
            [ -n "${numbootnodes}" ] && export BBAKE_NUMBOOTNODES=${numbootnodes}
            # export BBAKE_PYENV=
            [ -n "${quorum_src}" ] && export BBAKE_QUORUM_SRC=${quorum_src}
            [ -n "${recommit}" ] && export BBAKE_RECOMMIT=${recommit}
            [ -n "${rrr_image}" ] && export BBAKE_RRR_IMAGE=${rrr_image}
            [ -n "${rrr_src}" ] && export BBAKE_RRR_SRC=${rrr_src}
            [ -n "${rrrctl_image}" ] && export BBAKE_RRRCTL_IMAGE=${rrrctl_image}

            cd ${launchdir} && cd ${configdir}
            # ${UPDATE_CONFIG}
            cat bench.json

      - task:
          name: gethkeys
          args:
            - ${configdir}
      - task:
          # this is just to provide config for the loadtool. its ignored
          # otherwise
          name: gethstatic
          args:
            - ${configdir}
      - task:
          name: rrralpha
          args:
            - ${configdir}

      - task:
          name: rrrinit
          args:
            - ${configdir}

      - task:
          name: clientcfg
          args:
            - ${configdir}

      - task:
          name: rrropts
          args:
            - ${configdir}

      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir}

            CMD=gethcompose
            ${BBAKE_K8S} && CMD=gethk8s
            tusk -qf ${tuskdir}/tusk.yml ${CMD} ${configdir}

  configure:
    usage: >
      Put the runes for updating and showing the config file into an
      environment variable so that it can be more readily re-used. This enables
      both shell tusk tasks and python to share the same config, with minimal
      boiler plate.
    private: true
    args:
      configdir:
    options:
      required:
        usage: "list of values in the config requried by the task"
    run:
      - set-environment:
          SHOW_CONFIG: "for v in ${configvars}; do vv=BBAKE_${v^^}; echo ${vv}=${!vv}; done"
          UPDATE_CONFIG: python3 ${tuskdir}/benchjson.py update ${config} ${configvars}
          # This doesn't cope with variables whose values require embeded
          # spaces.
          # READ_CONFIG: "$(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)"

      - command:
          exec: |
            [ -z "${required}" ] && exit 0
            cd ${launchdir} && cd ${configdir}
            python3 ${tuskdir}/benchjson.py require ${config} ${required}
      # execute these fragments in the task like this:
      #   eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
      #   if ${configshow}; then eval ${SHOW_CONFIG}; exit 0; fi
      # bash variable substitution complexities prevent the read commands from
      # being expresed as a eval safe variable
  config-update:
    private: true
    run:
      - command:
          exec: cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py update ${config} ${configvars}

  gethgendoc:
    include: tuskfiles/gethgendoc.yml

  gethkeys:
    include: tuskfiles/gethkeys.yml

  gethgen:
    include: tuskfiles/gethgen.yml

  gethstatic:
    include: tuskfiles/gethstatic.yml

  clientcfg:
    include: tuskfiles/clientcfg.yml

  gethcompose:
    include: tuskfiles/gethcompose.yml

  gethk8s:
    include: tuskfiles/gethk8s.yml

  gethsealedsecrets:
    include: tuskfiles/gethsealedsecrets.yml

  # raft consensus commands
  raftopts:
    include: tuskfiles/raftopts.yml

  # ibft consensus commands
  ibftextra:
    include: tuskfiles/ibftextra.yml

  ibftopts:
    include: tuskfiles/ibftopts.yml

  # raft consensus commands

  # rrr consensus commands
  rrralpha:
    include: tuskfiles/rrralpha.yml

  rrrextra:
    include: tuskfiles/rrrextra.yml

  rrrinit:
    include: tuskfiles/rrrinit.yml

  rrropts:
    include: tuskfiles/rrropts.yml

  # general ergonomics
  knet:
    include: tuskfiles/knet.yml

  kex:
    usage: >
      execute a command in the nodes js console via kubectl exec
    options:
      node:
        short: "i"
        default: 0
        type: int
    args:
      configdir:
      exec:
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e
            # read the config file fields into BBAKE_ vars.
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            i=${node}
            POD=${BBAKE_NAME}-ethnode${i}-0
            export POD

            kubectl \
              $([ -z '${exec}' ] && echo -n '-it') \
              -n ${BBAKE_NAME} exec ${POD} -- \
              /usr/local/bin/geth \
              attach /data/node/geth.ipc \
                $([ -n '${exec}' ] && echo -n --exec '${exec}')

  wait-for-network-up:
    usage: wait for all nodes in a network to start (k8s only)
    options:
      maxwait:
        default: 180
      sleep:
        default: 3
      context:
      cluster:

    args:
      configdir:
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            CONTEXT=${context}
            CLUSTER=${cluster}
            KUBECTL="kubectl ${CONTEXT:+ --context $CONTEXT} ${CLUSTER:+ --cluster $CLUSTER}"

            WAIT_REMAINING=${maxwait}
            SLEEP=${sleep}

            while true; do

              NRUNNING=$(${KUBECTL} -n $BBAKE_NAME get pods \
                --field-selector=status.phase=Running \
                --output=jsonpath={.items..metadata.name} | wc -w)

              [ "${NRUNNING}" == "${BBAKE_MAXNODES}" ] && echo "ok: $NRUNNING nodes are ready" && break
              [ $((WAIT_REMAINING > 0)) -ne 1 ] && echo "maxwait exhausted" && exit -1
              WAIT_REMAINING=$((WAIT_REMAINING - SLEEP))

              echo "${NRUNNING} of ${BBAKE_MAXNODES} running. (attempts left $((WAIT_REMAINING / SLEEP)),  sleeping for ${SLEEP}s)"
              sleep ${SLEEP}
            done


  collectresults:
    usage: read and print the current block(k8s only)

    options:
      nodename:
        default: "ethnode0-0"
      start:
        default: 0

    args:
      configdir:
      end:

    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            CONTEXT=${context}
            CLUSTER=${cluster}
            KUBECTL="kubectl ${CONTEXT:+ --context $CONTEXT} ${CLUSTER:+ --cluster $CLUSTER}"

            ${KUBECTL} exec -n $BBAKE_NAME ${nodename} -- \
              geth attach /data/node/geth.ipc --exec eth.blockNumber

            kubectl port-forward -n $BBAKE_NAME ${nodename} 8300:8300 &
            PF_PID=$!

            BBETH=$GOBIN/bbeth
            [ ! -f "${BBETH}" ] && BBETH="./bbeth"
            [ ! -f "${BBETH}" ] && BBETH="bbeth"

            echo "STARTBLOCK: ${start}, ENDBLOCK: ${end}"
            ${BBETH} -e http://127.0.0.1:8300 --no-progress \
              collect --dbsource ${launchdir}/results.db -s ${start} --endblock ${end}

  blocknumber:
    usage: read and print the current block(k8s only)

    options:
      nodename:
        default: "ethnode0-0"
    args:
      configdir:

    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            CONTEXT=${context}
            CLUSTER=${cluster}
            KUBECTL="kubectl ${CONTEXT:+ --context $CONTEXT} ${CLUSTER:+ --cluster $CLUSTER}"

            ${KUBECTL} exec -n $BBAKE_NAME ${nodename} -- \
              geth attach /data/node/geth.ipc --exec eth.blockNumber

  wait-for-block:
    usage: read the current block then wait for a new one (k8s only)
    options:
      maxwait:
        default: 180
      sleep:
        default: 5

    args:
      configdir:

    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            CONTEXT=${context}
            CLUSTER=${cluster}
            KUBECTL="kubectl ${CONTEXT:+ --context $CONTEXT} ${CLUSTER:+ --cluster $CLUSTER}"

            WAIT_REMAINING=${maxwait}
            SLEEP=${sleep}
            echo "reading current block"

            # We could try any node, the first is present in all network
            # configurations so we use that
            NODENAME=ethnode0-0

            # read current block, if nodes are still starting we need to retry.
            while true; do


              START_BLOCK=$(${KUBECTL} exec -n $BBAKE_NAME $NODENAME -- \
                geth attach /data/node/geth.ipc --exec eth.blockNumber)

              if [[ $START_BLOCK =~ ^[0-9]+$ ]]; then
                echo "START_BLOCK: $START_BLOCK"
                break
              fi

              [ $((WAIT_REMAINING > 0)) -ne 1 ] && echo "maxwait exhausted" && exit -1
              WAIT_REMAINING=$((WAIT_REMAINING - SLEEP))
              echo "Waiting for current block. got=$START_BLOCK. (time left $WAIT_REMAINING, sleeping for ${SLEEP}s)"
              sleep $SLEEP
            done

            while true; do
              echo "Waiting for block to be produced. (attempts left $((WAIT_REMAINING / SLEEP)) sleeping for ${SLEEP}s"
              [ $((WAIT_REMAINING > 0)) -ne 1 ] && echo "maxwait exhausted" && exit -1
              WAIT_REMAINING=$((WAIT_REMAINING - SLEEP))
              sleep ${SLEEP}

              BLOCK=$(${KUBECTL} exec -n $BBAKE_NAME $NODENAME -- \
                geth attach /data/node/geth.ipc --exec eth.blockNumber)
              # it might be different because the exec fails in some way
              [ "$START_BLOCK" != "$BLOCK" ] && echo "eth.blockNumber changed: $START_BLOCK -> $BLOCK" && exit 0
            done

  wait-for-job:
    usage: wait for all nodes in a network to start (k8s only)
    options:
      maxwait:
        default: 180
        short: w
      sleep:
        default: 3
        short: s
      context:
      cluster:

    args:
      configdir:
      jobname:
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e
            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            CONTEXT=${context}
            CLUSTER=${cluster}
            KUBECTL="kubectl ${CONTEXT:+ --context $CONTEXT} ${CLUSTER:+ --cluster $CLUSTER}"

            WAIT_REMAINING=${maxwait}
            SLEEP=${sleep}

            # Wait for started
            while true; do

              STARTED=$(${KUBECTL}  -n $BBAKE_NAME get pods \
                --selector=job-name=${jobname} \
                -o jsonpath='{range .items[*]}{.status.containerStatuses[0].state.running.startedAt}')

              STATE=$(${KUBECTL}  -n $BBAKE_NAME get pods \
                --selector=job-name=${jobname} \
                -o jsonpath='{range .items[*]}{.status.containerStatuses[0].state.terminated.reason}')

              # deal with stale job first. its running state will be gone
              [ "$STATE" == "Completed" ] && echo "completed: ok" && break
              [ -n "$STATE" ] && echo "terminated: $STATE" && break

              [ -n "$STARTED" ] && echo "StartedAt: $STARTED" && STARTED=$(date -d $STARTED +%s) && break
              echo "Waiting for start. sleep ${SLEEP}s"
              sleep ${SLEEP}
            done

            while true; do

              STATE=$(${KUBECTL}  -n $BBAKE_NAME get pods \
                --selector=job-name=${jobname} \
                -o jsonpath='{range .items[*]}{.status.containerStatuses[0].state.terminated.reason}')

              if [ -n "${STARTED}" ]; then
                NOW=$(date +%s)
                RUNNINGFOR="Running for: $(TZ=UTC date -d @$((${NOW}-${STARTED})) +%H:%M:%S). "
              fi
              [ "$STATE" == "Completed" ] && echo "completed: ok" && break
              [ -n "$STATE" ] && echo "terminated: $STATE" && break


              [ $((WAIT_REMAINING > 0)) -ne 1 ] && echo "maxwait exhausted" && exit -1
              WAIT_REMAINING=$((WAIT_REMAINING - SLEEP))

              echo "${RUNNINGFOR}Sleeping for ${SLEEP}s"
              sleep ${SLEEP}

            done

  # jupyter reporting
  jpycfg:
    include: tuskfiles/jpycfg.yml

  jpyrender:
    include: tuskfiles/jpyrender.yml

  tonb:
    usage: "convert the markdown notebook to ipython notebook format"
    args:
      configdir:
        usage: >
          The config root directory.
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e

            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)
            cd ${launchdir} && cd ${configdir}

            source ${pyenv}/bin/activate
            cat standard-plots.md | jupytext --from .md --to notebook --output standard-plots.ipynb

  tomd:
    usage: "convert the ipython notebook format back to markdown"
    args:
      configdir:
        usage: >
          The config root directory.
    run:
      - task:
          name: configure
          args:
            - ${configdir}
      - command:
          exec: |
            set -e

            eval $(cd ${launchdir} && cd ${configdir} && python3 ${tuskdir}/benchjson.py shell-export bench.json)

            cd ${launchdir} && cd ${configdir}
            source ${pyenv}/bin/activate
            cat standard-plots.md | jupytext --from .md --to notebook --output standard-plots.ipynb
